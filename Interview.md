# `Data Science`

### Core : `Programming Skills` + `Maths and Statistics` + `Subject Matter Expert`

### Programming Skills : `Python` + `SQL` + `JavaScript (D3.js for Data Presentation)`

### Maths and Statistics : `Linear Algebra` + `Probability` + `Bayesian` + `Calculus`

### [DS + AI](https://github.com/KIRANKUMAR7296/Library/blob/main/AI/AI.md) | [ML](https://github.com/KIRANKUMAR7296/Library/blob/main/Machine%20Learning/Machine%20Learning%20Models.md) | [Real World Applications](https://github.com/KIRANKUMAR7296/Library/blob/main/Machine%20Learning/IBM%20Machine%20Learning.md) | [Elite](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Primer%20Steps.md) | [NLP](https://github.com/KIRANKUMAR7296/Library/blob/main/AI/Natural%20Language%20Processing.md) | [CV](https://github.com/KIRANKUMAR7296/Library/blob/main/AI/Computer%20Vision.md) | [P1](https://github.com/KIRANKUMAR7296/Distracted-Driver-Classification) | [P2](https://github.com/KIRANKUMAR7296/SMS-Classification) | [Predictive Analytics](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Predictive%20Analytics.md)

---

### [Python](https://github.com/KIRANKUMAR7296/Python) | [Data Types](https://github.com/KIRANKUMAR7296/Python/blob/main/Data%20Types.md) | [Pandas](https://github.com/KIRANKUMAR7296/Pandas) | [NumPy](https://github.com/KIRANKUMAR7296/NumPy) | [OOP](https://github.com/KIRANKUMAR7296/Python/blob/main/oop.md) | [Git](https://github.com/KIRANKUMAR7296/Library/blob/main/Git.md) | [SQL](https://github.com/KIRANKUMAR7296/SQL/blob/main/Queries.md) | [Image](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Flow.md) | [Power BI](https://github.com/KIRANKUMAR7296/PowerBI) | [Tableau](https://github.com/KIRANKUMAR7296/Tableau) | [Visualization](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Data%20Visualization.md)

---

### [Linear Regression](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Supervised%20Learning/Regression/Linear%20Regression.md) | [Logistic Regression](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Supervised%20Learning/Classification/Logistic%20Regression.md)  | [Metrics](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Supervised%20Learning/Regression/Regression%20Metrics.md) | [Regularization](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Regularization.md) | [Ensemble Techniques](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Supervised%20Learning/Ensemble%20Techniques.md)
 
---

### [Statistics](https://github.com/KIRANKUMAR7296/Library/blob/main/Statistics/Statistics.md) | [Terms](https://github.com/KIRANKUMAR7296/Library/blob/main/Statistics/Important%20Statistical%20Terms.md) | [Distribution](https://github.com/KIRANKUMAR7296/Library/blob/main/Statistics/Distribution.md) | [Standardization](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Normalization%20vs%20Standardization.md) | [Error](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Error.md) | [Bias and Variance](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Bias%20and%20Variance.md) | [Gradient Descent](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Gradient%20Descent.md)

--- 

### [Cross Validation](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Cross%20Validation.md) | [Multiclass vs Multilabel](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Multi%20Class%20and%20Multi%20Label%20Classification.md) | [Dimensionality Reduction](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Unsupervised%20Learning/Dimensionality%20Reduction.md) | [Algorithm Selection](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Steps/Algorithm%20Selection.md)

---

### [Missing Data](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Missing%20Data.md) | [Outliers](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Outliers.md) | [Categorical Feature](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Categorical.md) | [Imbalanced Data](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Imbalanced%20Dataset.md) | [Overfitting](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Overfitting.md) | [Data Cleaning](https://github.com/KIRANKUMAR7296/Library/blob/main/Data%20Science/Data%20Cleaning.md)

---

### [Pandas vs SQL](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_sql.html#join) | [Lists vs Array](https://github.com/KIRANKUMAR7296/NumPy)

> Outliers : Extreme Value Analysis | DBSCAN | 5 Number Summary | Algorithm ( KNN & Random Forest )

> Imbalanced : Up & Down Sampling | F1 Score | Stratified K Fold Cross Validation | Random Forest ( class_weight )

> Overfitting : Apply Regularization | Apply Ensembles | Apply Cross Validation | Feature Selection

**Time** Complexity of Occurence of Characters in a String : `O(n)`

### Log Function
- `Log` is inverse of `exponent`
- e.g. Base investment : `5₹` and 5 times return : `125₹` ( Log<sub>5</sub> 125 : `3` Years )
- Log<sub>5</sub> 5<sup>3</sup> = 3 ( i.e. 3 * Log<sub>5</sub>5 = 3 * `1` | Log<sub>5</sub>5 = 1 )

### PyTest
- A testing framework for Python that simplifies the process of writing and executing tests.
- It provides an easy-to-use and expressive syntax for creating test cases, running tests, and reporting the results.

### Model = Algorithm ( Parameters ) + Data

### Data Pipeline ( Where and how the data are collected, transformed and loaded ) 
- A set of actions that `extract` data from various **sources**, `transform` it into proper format and `load` for processing.
- An automated process :
1. Select `columns` from database.
2. `Merge` columns from two or more tables. 
3. `Subset` rows ( Sample ) 
4. Handle `missing` data.
5. `Load` them in other database.
- First time the process is complicated but if you do it right you will have to do it just once.
- To have automation you need to think, plan and write in Simple Language, keep it reproducible. 

### Data Lake
- A storage repository where data is stored in its natural | raw format without applying any transformation.
- Data warehouse uses files or folders structure, data lakes uses flat architecture.

### Important Disclaimer
- We try to make out **model** more **accurate** by **tuning** and **tweaking** the **parameters**.
- But we cannot make a `100%` accurate model.
- `Prediction` and `classification` models, can never be **error free**.

> **Y** = f ( **x** ) + **e**

**Y** : Response Variable | Dependent Variable

**x** : Independent variable

**e** : Irreducible error ( Even we make a **100%** accurate estimate of **f ( x )**, Our model can't be **error free**, known as **irreducible error** )

### Activation Function
- A function that takes in the **weighted sum** of all the inputs from **previous layer** adds **bias** and generates output for **next layer**.

### Hyperparameter Optimization
- Finding **ideal** set of **parameters** for a prediction algorithm with optimum performance.

Parameter | Hyperparameter
:--- | :---
Automatically learns while training | Manually tuned by the developer to guide the training.
Weights and bias are the model parameters | Learning rate, depth of tree, class weights.
`Internal` configuration variables of the model | `External` configuration variables of the model.

Data Ware House | Data Lake
:--- | :---
Structured + Pre-processed | Unstructured + Semi Structured + Structured + Raw
Organized before storing | Organized before using
Business professionals, Analyst, BI and Visualizations | **Data Scientists**, **Analytics** and **AI**

| DBMS | RDBMS |
| :--- | :---  |
| Store data in the form of **file** | Store data in the form of **tables** |
| **Hierarchical** arrangement of data | **Rows** and **columns** ( **Tables** ) |
| Manage **data** in computer | Maintain **relationships** of **table** in a **database** |

| Classification | Clustering |
| :--- | :---  |
| Need **prior** knowledge of data | **No prior** knowledge of data |
| Classify new sample into known **classes** | Suggest groups based on **patterns** in data |
| **Decision tree** | **K Means** |
| **Labelled** samples | **Unlabelled** samples |

LDA | PCA
:--- | :---
Linear Discriminant Analysis | Principle Component Analysis
Supervised | Unsupervised

K Means | K Nearest Neighbor
:--- | :---
Unsupervised | Supervised
K : Number of **clusters** | K : Number of **nearest** neighbors.
Determine the distances of each data points to the **centroid** and assign each point to closest cluster **centroid** | **Calculate** distance between **new** data point with **nearest** K neighbours.

Variance `s` <sup>2</sup> | Standard Deviation `s`
:--- | :---
Distance `between` the `data points` in the dataset |  Distance of a data point from the `mean` of the dataset

Variance | Covariance
:--- | :---
**Magnitude** | **Magnitude** and **Direction**
**Data points** from its `mean` | Data points **varies** with respect to each other.

### Which Algorithm Generates the Best Model ?

Accuracy | Latency
:--- | :---
How they handle data of different size ? | How long will it take to **train** the model ?
How will they handle complexity of feature relationships ? | How long will it take to **predict** the dependent variables ?
How will they handle messy data ( Missing Data + Outliers )

### Autocorrelation
- The **correlation** of the `data point` with a delayed copy of itself. 
- Temperature of the day **today** vs temperature of the day **yesterday** or **tommorrow**.

### Multicollinearity 
- A phenomenon in which at least two **independent variables** are **linearly correlated** ( One can be `predicted` from the other )

### Cross Join | Cartesian Product
- Generate **paired** combination of each **row** of **first** table with each **row** of the **second** table.

### Data Scientist Steps 
1. Explore ( EDA ) and clean ( Data Cleaning ) the data.
2. Split data into train + validate + test sets.
3. Train with an initial model and evaluate.
4. Tune hyperparameters + cross validations ( Assurance of accuracy ) 
5. Evaluate on validation set ( Performance )  
6. Evaluate on test set ( Prediction )
